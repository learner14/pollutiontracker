{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38f0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "import hsfs\n",
    "import great_expectations as ge\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d047af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_historical_weather(city, start_date,  end_date, latitude, longitude):\n",
    "    # latitude, longitude = get_city_coordinates(city)\n",
    "\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "    # Make sure all required weather variables are listed here\n",
    "    # The order of variables in hourly or daily is important to assign them correctly below\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": [\"temperature_2m_mean\", \"precipitation_sum\", \"wind_speed_10m_max\", \"wind_direction_10m_dominant\"]\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    # Process first location. Add a for-loop for multiple locations or weather models\n",
    "    response = responses[0]\n",
    "    print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "    print(f\"Elevation {response.Elevation()} m asl\")\n",
    "    print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "    print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "    # Process daily data. The order of variables needs to be the same as requested.\n",
    "    daily = response.Daily()\n",
    "    daily_temperature_2m_mean = daily.Variables(0).ValuesAsNumpy()\n",
    "    daily_precipitation_sum = daily.Variables(1).ValuesAsNumpy()\n",
    "    daily_wind_speed_10m_max = daily.Variables(2).ValuesAsNumpy()\n",
    "    daily_wind_direction_10m_dominant = daily.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    daily_data = {\"date\": pd.date_range(\n",
    "        start = pd.to_datetime(daily.Time(), unit = \"s\"),\n",
    "        end = pd.to_datetime(daily.TimeEnd(), unit = \"s\"),\n",
    "        freq = pd.Timedelta(seconds = daily.Interval()),\n",
    "        inclusive = \"left\"\n",
    "    )}\n",
    "    daily_data[\"temperature_2m_mean\"] = daily_temperature_2m_mean\n",
    "    daily_data[\"precipitation_sum\"] = daily_precipitation_sum\n",
    "    daily_data[\"wind_speed_10m_max\"] = daily_wind_speed_10m_max\n",
    "    daily_data[\"wind_direction_10m_dominant\"] = daily_wind_direction_10m_dominant\n",
    "\n",
    "    daily_dataframe = pd.DataFrame(data = daily_data)\n",
    "    daily_dataframe = daily_dataframe.dropna()\n",
    "    daily_dataframe['city'] = city\n",
    "    return daily_dataframe\n",
    "\n",
    "def get_hourly_weather_forecast(city, latitude, longitude):\n",
    "\n",
    "    # latitude, longitude = get_city_coordinates(city)\n",
    "\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "    # Make sure all required weather variables are listed here\n",
    "    # The order of variables in hourly or daily is important to assign them correctly below\n",
    "    url = \"https://api.open-meteo.com/v1/ecmwf\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": [\"temperature_2m\", \"precipitation\", \"wind_speed_10m\", \"wind_direction_10m\"]\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    # Process first location. Add a for-loop for multiple locations or weather models\n",
    "    response = responses[0]\n",
    "    print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "    print(f\"Elevation {response.Elevation()} m asl\")\n",
    "    print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "    print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "    # Process hourly data. The order of variables needs to be the same as requested.\n",
    "\n",
    "    hourly = response.Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "    hourly_precipitation = hourly.Variables(1).ValuesAsNumpy()\n",
    "    hourly_wind_speed_10m = hourly.Variables(2).ValuesAsNumpy()\n",
    "    hourly_wind_direction_10m = hourly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    hourly_data = {\"date\": pd.date_range(\n",
    "        start = pd.to_datetime(hourly.Time(), unit = \"s\"),\n",
    "        end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\"),\n",
    "        freq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "        inclusive = \"left\"\n",
    "    )}\n",
    "    hourly_data[\"temperature_2m_mean\"] = hourly_temperature_2m\n",
    "    hourly_data[\"precipitation_sum\"] = hourly_precipitation\n",
    "    hourly_data[\"wind_speed_10m_max\"] = hourly_wind_speed_10m\n",
    "    hourly_data[\"wind_direction_10m_dominant\"] = hourly_wind_direction_10m\n",
    "\n",
    "    hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "    hourly_dataframe = hourly_dataframe.dropna()\n",
    "    return hourly_dataframe\n",
    "\n",
    "\n",
    "\n",
    "def get_city_coordinates(city_name: str):\n",
    "    \"\"\"\n",
    "    Takes city name and returns its latitude and longitude (rounded to 2 digits after dot).\n",
    "    \"\"\"\n",
    "    # Initialize Nominatim API (for getting lat and long of the city)\n",
    "    user_agent = \"Hopsworks air quality predictor/1.0 (contact: jim@hopsworks.ai)\"\n",
    "    geolocator = Nominatim(user_agent=user_agent)\n",
    "    city = geolocator.geocode(city_name)\n",
    "\n",
    "    latitude = round(city.latitude, 2)\n",
    "    longitude = round(city.longitude, 2)\n",
    "\n",
    "    return latitude, longitude\n",
    "\n",
    "def trigger_request(url:str):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the JSON content from the response\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(\"Failed to retrieve data. Status Code:\", response.status_code)\n",
    "        raise requests.exceptions.RequestException(response.status_code)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_pm25(aqicn_url: str, country: str, city: str, street: str, day: datetime.date, AQI_API_KEY: str):\n",
    "    \"\"\"\n",
    "    Returns DataFrame with air quality (pm25) as dataframe\n",
    "    \"\"\"\n",
    "    # The API endpoint URL\n",
    "    url = f\"{aqicn_url}/?token={AQI_API_KEY}\"\n",
    "\n",
    "    # Make a GET request to fetch the data from the API\n",
    "    data = trigger_request(url)\n",
    "\n",
    "    # if we get 'Unknown station' response then retry with city in url\n",
    "    if data['data'] == \"Unknown station\":\n",
    "        url1 = f\"https://api.waqi.info/feed/{country}/{street}/?token={AQI_API_KEY}\"\n",
    "        data = trigger_request(url1)\n",
    "\n",
    "    if data['data'] == \"Unknown station\":\n",
    "        url2 = f\"https://api.waqi.info/feed/{country}/{city}/{street}/?token={AQI_API_KEY}\"\n",
    "        data = trigger_request(url2)\n",
    "\n",
    "\n",
    "    # Check if the API response contains the data\n",
    "    if data['status'] == 'ok':\n",
    "        # Extract the air quality data\n",
    "        aqi_data = data['data']\n",
    "        aq_today_df = pd.DataFrame()\n",
    "        aq_today_df['pm25'] = [aqi_data['iaqi'].get('pm25', {}).get('v', None)]\n",
    "        aq_today_df['pm25'] = aq_today_df['pm25'].astype('float32')\n",
    "\n",
    "        aq_today_df['country'] = country\n",
    "        aq_today_df['city'] = city\n",
    "        aq_today_df['street'] = street\n",
    "        aq_today_df['date'] = day\n",
    "        aq_today_df['date'] = pd.to_datetime(aq_today_df['date'])\n",
    "        aq_today_df['url'] = aqicn_url\n",
    "    else:\n",
    "        print(\"Error: There may be an incorrect  URL for your Sensor or it is not contactable right now. The API response does not contain data.  Error message:\", data['data'])\n",
    "        raise requests.exceptions.RequestException(data['data'])\n",
    "\n",
    "    return aq_today_df\n",
    "\n",
    "\n",
    "\n",
    "def delete_feature_groups(fs, name):\n",
    "    try:\n",
    "        for fg in fs.get_feature_groups(name):\n",
    "            fg.delete()\n",
    "            print(f\"Deleted {fg.name}/{fg.version}\")\n",
    "    except hsfs.client.exceptions.RestAPIError:\n",
    "        print(f\"No {name} feature group found\")\n",
    "\n",
    "def delete_feature_views(fs, name):\n",
    "    try:\n",
    "        for fv in fs.get_feature_views(name):\n",
    "            fv.delete()\n",
    "            print(f\"Deleted {fv.name}/{fv.version}\")\n",
    "    except hsfs.client.exceptions.RestAPIError:\n",
    "        print(f\"No {name} feature view found\")\n",
    "\n",
    "def delete_models(mr, name):\n",
    "    models = mr.get_models(name)\n",
    "    if not models:\n",
    "        print(f\"No {name} model found\")\n",
    "    for model in models:\n",
    "        model.delete()\n",
    "        print(f\"Deleted model {model.name}/{model.version}\")\n",
    "\n",
    "def delete_secrets(proj, name):\n",
    "    secrets = secrets_api(proj.name)\n",
    "    try:\n",
    "        secret = secrets.get_secret(name)\n",
    "        secret.delete()\n",
    "        print(f\"Deleted secret {name}\")\n",
    "    except hopsworks.client.exceptions.RestAPIError:\n",
    "        print(f\"No {name} secret found\")\n",
    "\n",
    "# WARNING - this will wipe out all your feature data and models\n",
    "def purge_project(proj):\n",
    "    fs = proj.get_feature_store()\n",
    "    mr = proj.get_model_registry()\n",
    "\n",
    "    # Delete Feature Views before deleting the feature groups\n",
    "    delete_feature_views(fs, \"air_quality_fv\")\n",
    "\n",
    "    # Delete ALL Feature Groups\n",
    "    delete_feature_groups(fs, \"air_quality\")\n",
    "    delete_feature_groups(fs, \"weather\")\n",
    "    delete_feature_groups(fs, \"aq_predictions\")\n",
    "\n",
    "    # Delete all Models\n",
    "    delete_models(mr, \"air_quality_xgboost_model\")\n",
    "    delete_secrets(proj, \"SENSOR_LOCATION_JSON\")\n",
    "\n",
    "def check_file_path(file_path):\n",
    "    my_file = Path(file_path)\n",
    "    if my_file.is_file() == False:\n",
    "        print(f\"Error. File not found at the path: {file_path} \")\n",
    "    else:\n",
    "        print(f\"File successfully found at the path: {file_path}\")\n",
    "\n",
    "def backfill_predictions_for_monitoring(weather_fg, air_quality_df, monitor_fg, model):\n",
    "    features_df = weather_fg.read()\n",
    "    features_df = features_df.sort_values(by=['date'], ascending=True)\n",
    "    features_df = features_df.tail(10)\n",
    "    features_df['predicted_pm25'] = model.predict(features_df[['temperature_2m_mean', 'precipitation_sum', 'wind_speed_10m_max', 'wind_direction_10m_dominant']])\n",
    "    df = pd.merge(features_df, air_quality_df[['date','pm25','street','country']], on=\"date\")\n",
    "    df['days_before_forecast_day'] = 1\n",
    "    hindcast_df = df\n",
    "    df = df.drop('pm25', axis=1)\n",
    "    monitor_fg.insert(df, write_options={\"wait_for_job\": True})\n",
    "    return hindcast_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdc5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f609acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-05 19:54:50,673 INFO: Initializing external client\n",
      "2026-02-05 19:54:50,674 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-02-05 19:54:52,203 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/4234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"USA\", \"city\": \"Greensboro\", \"street\": \"oakridge road\", \"aqicn_url\": \"https://api.waqi.info/feed/@8883\", \"latitude\": 36.07, \"longitude\": -79.79}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = hopsworks.login(\n",
    "    project='airquality',  # Replace with your project name\n",
    "    host=\"eu-west.cloud.hopsworks.ai\",\n",
    "    port=443,\n",
    "    api_key_value=\"GJlAnxKNnkcak0We.eq0JNi6qAEQT2CKmdLbvYhMIi3v8iLAbHikBmTEj3jAi4B2Y1FCe9jbWtr9EZqU3\"  # Get from Hopsworks UI > Account Settings > API Keys\n",
    ")\n",
    "\n",
    "\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a2d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe32701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>Greensboro</td>\n",
       "      <td>oakridge road</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>https://api.waqi.info/feed/@8883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25 country        city         street       date  \\\n",
       "0  50.0     USA  Greensboro  oakridge road 2026-02-05   \n",
       "\n",
       "                                url  \n",
       "0  https://api.waqi.info/feed/@8883  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "aq_today_df = get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae4bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 36.0°N -79.75°E\n",
      "Elevation 255.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "source": [
    "hourly_df = get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4c60765",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44f72a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-05 20:10:48,149 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://eu-west.cloud.hopsworks.ai:443/p/4234/fs/5204/fg/7182\n",
      "2026-02-05 20:11:12,588 INFO: Computing insert statistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9217\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 50.0,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2026-02-06T01:10:48.000148Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2026-02-05T20:10:48.148786-05:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"abba908e-02f8-11f1-beb6-16e9927b249f\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20260206T011048.148615Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4abead6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-05 20:11:33,942 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://eu-west.cloud.hopsworks.ai:443/p/4234/fs/5204/fg/7183\n",
      "2026-02-05 20:11:58,021 INFO: Computing insert statistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9218\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 4.829906940460205,\n",
       "         \"element_count\": 7,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2026-02-06T01:11:33.000942Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9219\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 7,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2026-02-06T01:11:33.000942Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2026-02-05T20:11:33.942423-05:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"c7063af0-02f8-11f1-beb6-16e9927b249f\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20260206T011133.942335Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c18f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
